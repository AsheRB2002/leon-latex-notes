\documentclass{article}
% \usepackage{showframe}

% \usepackage[dvipsnames]{xcolor}
% custom colour definitions
% \colorlet{colour1}{Red}
% \colorlet{colour2}{Green}
% \colorlet{colour3}{Cerulean}

\usepackage{geometry}
% margins
\geometry{
    a4paper,
    bottom=70pt,
    % margin=70pt
}

\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
% \usepackage{preamble}
\usepackage{multicol}
\usepackage{lipsum}
\usepackage{float}
\usepackage[nodisplayskipstretch]{setspace}

% tikz and theorem boxes
\usepackage[framemethod=TikZ]{mdframed}
\usepackage{../thmboxes_v2}
% \usepackage{thmboxes_col}


\usepackage{hyperref} % note: this is the final package
\hypersetup{
  colorlinks   = true,    % Colours links instead of ugly boxes
  urlcolor     = blue,    % Colour for external hyperlinks
  linkcolor    = blue,    % Colour of internal links
  citecolor    = red      % Colour of citations
}


\parindent = 0pt
\linespread{1.1}

% Custom Definitions of operators
\DeclareMathOperator{\Ima}{im}
\DeclareMathOperator{\Fix}{Fix}
\DeclareMathOperator{\Orb}{Orb}
\DeclareMathOperator{\Stab}{Stab}
\DeclareMathOperator{\send}{send}
\DeclareMathOperator{\dom}{dom}

\title{Honours Algebra Notes}
\author{Leon Lee}
\renewcommand\labelitemi{\tiny$\bullet$}

\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage

\section{Vector Spaces}
\subsection{Fields and Vector Spaces}

\begin{dfn}[Definition of a field]{def:field}{}
    A \textbf{field} $F$ is a set with functions
    \begin{itemize}
        \item Addition: $+ : F \times F \to F,\,(\lambda, \mu) \mapsto \lambda + \mu$
        \item Multiplication: $\cdot : F \times F,\, (\lambda, \mu) \mapsto \lambda\mu$
    \end{itemize}
    and two distinguished members $0_{F},\, 1_{F}$ with $0_{F}\ne 1_{F}$ s.t. $(F,\, +)$ and $F \backslash \{0_{F},\, \cdot\}$ are \textit{abelian groups} whose neutral elements are $0_{F}$ and $1_{F}$ respectively, and which also satisifies
    \[\lambda(\mu + \nu) = \lambda\mu + \lambda\nu \in F\]
    for any $\lambda, \mu, \nu\in F$. 
    Additional Requirements: For all $\lambda,\mu\in F$,
    \begin{itemize}
        \item $\lambda + \mu = \mu + \lambda$
        \item $\lambda \cdot \mu = \mu \cdot \lambda$
        \item $\lambda + 0_{F} = \lambda$
        \item $\lambda \cdot 1_{F} = \lambda\in F$
    \end{itemize}
    For every $\lambda\in F$ there exists $-\lambda \in F$ such that
    \[\lambda + (-\lambda) = 0_{F} \in F\]
    For every $\lambda \ne 0 \in F$ there exists $\lambda^{-1}\ne 0\in F$ such that
    \[\lambda(\lambda^{-1}) = 1_{F}\in F\]

    NOTE: This is a terrible definition of a field, just think of it as a group with two operations instead of one
\end{dfn}

\begin{dfn}[Definition of a Vector Space]{def:vector-space}{}
    A \textbf{vector space $V$ over a field} $F$ is a pair consisting of an abelian group $V = (V,\, \dot{+})$ and a mapping
    \[F \times V \to V : (\lambda, \vec{v})\mapsto \lambda \vec{v}\]
    such that for all $\lambda, \mu \in F$ and $\vec{v}, \vec{w}\in V$ the following identities hold:
    \begin{align*}
        \lambda(\vec{v} \dot{+} \vec{w}) &= (\lambda\vec{v}) \dot{+} (\lambda \vec{w})\\
        (\lambda + \mu)\vec{v} &= (\lambda \vec{v}) \dot{+} (\mu \vec{v})\\
        \lambda (\mu \vec{v}) &= (\lambda \mu) \vec{v}\\
        1_{F}\vec{v} &= \vec{v}
    \end{align*}
    The first two laws are the \textbf{Distributive Laws}, the third law is called the \textbf{Associativity Law}. A vector field $V$ over a field $F$ is commonly called an \textbf{$F$-vector space}
\end{dfn}

\newpage

\subsubsection{Vector Space Terminology}
\begin{itemize}
    \item Elements of a vector space: \textbf{vectors}
    \item Elements of the field $F$: \textbf{scalars}
    \item The field $F$ itself: \textbf{ground field}
    \item The map $(\lambda, \vec{v})\mapsto \lambda\vec{v}$: \textbf{multiplication by scalars}, or the \textbf{action of the field $F$ on $V$}
\end{itemize}

\textbf{Notes}:
\begin{itemize}
    \item This is not the same as the "scalar product", as that produces a scalar from two vectors
    \item Let the zero element of the abelian group $V$ be written as $\vec{0}$ and called the \textbf{zero vector}
    \item The use of $\dot{+}$ and $1_{F}$ is there for mostly pedantic rigorous reasons, and a much less confusing way of defining a vector field is defined below:
\end{itemize}


\begin{dfn}[Alternative Vector Space definition]{def:vector-space-alt}{}
    A \textbf{vector space $V$ over a field} $F$ is a pair consisting of an abelian group $V = (V,\, \dot{+})$ and a mapping
    \[F \times V \to V : (\lambda, \vec{v})\mapsto \lambda \vec{v}\]
    such that for all $\lambda, \mu \in F$ and $\vec{v}, \vec{w}\in V$ the following identities hold:
    \begin{align*}
        \lambda(\vec{v} \dot{+} \vec{w}) &= \lambda\vec{v} \dot{+} \lambda \vec{w}\\
        (\lambda + \mu)\vec{v} &= \lambda \vec{v} \dot{+} \mu \vec{v}\\
        \lambda (\mu \vec{v}) &= (\lambda \mu) \vec{v}\\
        1\vec{v} &= \vec{v}
    \end{align*}
\end{dfn}

\noindent\rule{\textwidth}{0.2pt}

\subsubsection{Vector Space Lemmas}

\textbf{Product with the scalar zero}: If $V$ is a \textit{vector space} and $\vec{v}\in V$, then $0\vec{v} = \vec{0}$, or in words "zero times a vector is the zero vector"

\textbf{Product with the scalar $(-1)$}: If $V$ is a \textit{vector space} and $\vec{v}\in V$, then $(-1)\vec{v} = - \vec{v}$

\textbf{Product with the zero vector}: If $V$ is a \textit{vector space} over a field $F$, then $\lambda \vec{0} = \vec{0}$ for all $\lambda\in F$. Furthermore, if $\lambda \vec{v} = \vec{0}$ then either $\lambda = 0$ or $@\vec{v} = \vec{0}$

\newpage
\subsection{Product of Sets and of Vector Spaces}

\begin{dfn}[Cartesian Product of $n$ sets]{def:cartesian-prod}{}
    Trivially: $X \times Y = \{(x,y) : x\in X,\,y\in Y\}$

    Just extend this to $n$ numbers
    \[X_{1} \times \cdots \times X_{n} := \{(x_{1}, \dots, x_{n}) : x_{i}\in X_{i} \text{ for } 1 \le i \le n\}\]

    The elements of a product are called \textbf{$n$-tuples}. An individual entry $x_{i} = (x_{1}, \dots ,x_{n})$ is called a \textbf{component}.

    There are special mappings called \textbf{projections} for a cartesian product:
    \begin{align*}
        \text{pr}_{i} : X_{1} \times \cdots \times X_{n} &\to X_{i}\\
        (x_{1},\dots,x_{n}) &\mapsto x_{i}
    \end{align*}

    The cartesian product of $n$ copies of a set $X$ is written in short as: $X^{n}$
\end{dfn}

The elements of $X^{n}$ are $n$-tuples of elements from $X$. In the special case $n = 0$ we use the general convention that $X^{0}$ is "the" one element set, so that for all $n,m\ge 0$, we then have the canonical bijection
\begin{align*}
    X^{n} \times X^{m} &\to X^{n + m} \\
    ((x_{1},x_{2},\dots,x_{n}),\,(x_{n+1}, x_{n+2},\dots,x_{n+m})) &\mapsto (x_{1},x_{2},\dots,x_{n},x_{n+1},x_{n+2},\dots,x_{n+m})
\end{align*}
Note: the $\to$ should have a tilde but idk how to typeset it like that

[ Bunch of examples: check LN 1.3]

\subsection{Vector Subspaces}

\begin{dfn}[Vector Subspace]{def:vector-subspace}{}
    A subset $U$ of a vector space $V$ is called a \textbf{vector subspace} or \textbf{subspace} if $U$ contains the zero vector, and whenever $\vec{u},\vec{v}\in U$ and $\lambda\in F$ we have $\vec{u} + \vec{v}\in U$ and $\lambda \vec{u}\in U$
\end{dfn}

\textbf{Note} There is a more generalized definition using concepts we haven't learned yet, it is as follows: Let $F$ be a field. A subset of an $F$-vector space is called a vector subspace if it can be given the structure of an $F$-vector space such that the embedding is a "homomorphism of $F$-vector spaces". This definition is a lot more general since it also applies to subgroups, subfields, sub-"any structure", etc

\begin{dfn}[Spanning Subspace]{def:spanning-subspace}{}
    Let $T$ be a subset of a vector space $V$ over a field $F$. Then amongst all vector subspaces of $V$ that include $T$ there is a smallest vector subspace
    \[\langle T \rangle = \langle T \rangle_{F} \subseteq V\]
    It can be described as the set of all vectors $\alpha_{1}\vec{v}_{1} + \cdots + \alpha_{r}\vec{v}_{r}$ with $\alpha_{1},\dots,\alpha_{r}\in F$ and $\vec{v}_{1},\dots,\vec{v}_{r}\in T$, together with the zero vector in the case $T = \emptyset$
\end{dfn}

\subsubsection{Subspace terminology}
\begin{itemize}
    \item An expression of the form $a_{1}\vec{v}_{1} + \cdots + \alpha_{r} \vec{v}_{r}$ is called a \textbf{linear combination} of vectors $\vec{v}_{1},\dots,\vec{v}_{r}$.
    \item The smallest vector subspace $\langle T \rangle \subseteq V$ containing $T$ is called the \textbf{vector subspace generated by $T$} or the vector subspace \textbf{spanned by $T$} or even the \textbf{span of $T$}
    \item If we allow the zero vector to be the "empty linear combination of $r = 0$ vectors", which is what we will mean from hereon, then the span of $T$ is exactly the set of all linear combinations of vectors from $T$
\end{itemize}

\begin{dfn}[Generating Subspace]{def:generating-subspace}{Number}
    A subset of a vector space is called a \textbf{generating} or \textbf{spanning set} of our vector space if its span is all of the vector space. A vector space that has a finite generating set is said to be \textbf{finitely generated}.
\end{dfn}

\subsection{Linear Independence and Bases}

\begin{dfn}[Linear Independence]{def:linear-independence}{}
    A subset $L$ of a vector space $V$ is called \textbf{linearly independent} if for all pairwise different vectors $\vec{v}_{1},\dots,\vec{v}_{r}\in L$ and arbitrary scalars $\alpha,\dots,\alpha_{r}\in F$,
    \[a_{1}\vec{v}_{1} + \cdots + \alpha_{r}\vec{v}_{r} = \vec{0} \implies a_{1} = \cdots = \alpha_{r} = 0\]
\end{dfn}

\begin{dfn}[Linear Dependence]{def:linear-dependence}{}
    A subset $L$ of a vector space $V$ is called \textbf{ilnearly dependent} if it is not linearly independent (duh..). This means there exists pairwise different vectors $\vec{v}j_{1},\dots,\vec{v}_{r}\in L$ and scalars $\alpha_{1},\dots,\alpha_{r}\in F$, not all zero, such that $\alpha_{1}\vec{v}_{1} + \cdots \alpha_{r}\vec{v}_{r} = \vec{0}$
\end{dfn}

\begin{dfn}[Basis of a Vector Space]{def:basis}{}
    A \textbf{basis of a vector space} $V$ is a linearly independent generating set in $V$
\end{dfn}

\subsubsection{Family notation}
Let $A$ and $I$ be sets. We will refer to a mapping $I\to A$ as a \textbf{family of elements of $A$ indexed by $I$} and use the notation
\[(a_{i})i\in I\]

This is used mainly when $I$ plays a secondary role to $A$. In the case $I = \emptyset$, we will talk about the \textbf{empty family} of elements of $A$.

Random facts:
\begin{itemize}
    \item The family $(\vec{v}_{i})_{i\in I}$ would be called a generating set if the set $\{\vec{v}_{i} : i\in I\}$ is a generating set.
    \item It would be called \textbf{linearly independent} or a \textbf{linearly independent family} if, for pairwise distinct indices $i(1),\dots,i(r)\in I$ and arbitrary scalars $a_{1},\dots,a_{r}\in F$,
        \[a_{1}\vec{v}_{i(1)} + \cdots + a_{r}\vec{v}_{i(r)} = \vec{0} \to \alpha_{1} = \cdots = a_{r} = 0\]
\end{itemize}

A difference between families and subsets is that the same vector can be represented by different indices in a family, in which case linear independence as a family is not possible. A family of vectors that is not linearly independent is called a \textbf{linearly dependent family}. A family of vectors that is a generating set and linearly independent is called either a \textbf{basis} or a \textbf{basis indexed by} $i\in I$

\begin{xmp}[Standard Basis]{xmp:standard-basis}{}
    Let $F$ be a field and $n\in \mathbb{N}$. We consider the following vectors in $F^{n}$
    \[\vec{e}_{i} = (0,\dots,0,1,0,\dots,0)\]
    with one $1$ in the $i$-th place and zero everywhere else. Then $\vec{e}_{1} ,\dots, \vec{e}_{n}$ form an ordered basis of $F^{n}$, the so-called \textbf{standard basis of $F^{n}$}
\end{xmp}

\begin{thm}[Linear combinations of basis elements]{thm:linear-combinations-of-basis-elems}{}
    Let $F$ be a field, $V$ a vector space over $F$ and $\vec{v}_{1},\dots,\vec{v}_{r}\in V$ vectors. The family $(\vec{v}_{i})_{1\le i\le r}$ is a basis of $V$ if and only if the following "evaluation" mapping
    \begin{align*}
        \psi : F^{r} &\to V\\
        (\alpha_{1},\dots,a_{r}) &\mapsto a_{1}\vec{v}_{1} + \cdots + \alpha_{r}\vec{v}_{r}
    \end{align*}
    is a bijection

    If we label our ordered family by $\mathcal{A} = (\vec{v}_{1},\dots,\vec{v}_{r})$, then we done the above mapping by
    \[\psi = \psi_{\mathcal{A}} : F^{r}\to V\]
\end{thm}

\newpage
\section{Rings}
I can't be bothered doing changes of basis and stuff, time for something more interesting :D 

\subsection{Ring basics}
\begin{dfn}[Definition of a Ring]{def:ring}{}
    A \textbf{ring} is a set with two operations $(\mathbb{R}, +, \cdot)$ that satisfy:
    \begin{enumerate}
        \item $(R, +)$ is an abelian group
        \item $(R, \cdot)$ is a \textbf{monoid} - this means that the second operation $\cdot : R \times R \to R$ is associative and that there is an \textbf{identity element} $1 = 1_{R}\in R$, often just called the identity, with the property that $1 \cdot a = a \cdot 1 = a$ for all $a\in R$.
        \item The distributive laws hold, meaning that for all $a,b,c\in R$,
            \begin{align*}
                a \cdot (b + c) &= (a \cdot b) + (a \cdot c)) \\
                (a + b) \cdot c &= (a \cdot c) + (b \cdot c)
            \end{align*}
    \end{enumerate}
    The two operations are called \textbf{addition} and \textbf{multiplication} in our ring. A ring in which multiplication, that is $a \cdot b = b \cdot a$ for all $a,b\in R$, is a \textbf{commutative ring}
\end{dfn}

\textbf{Note}: We'll call the element $1\in R$ as the identity element of the monoid $(R, \cdot)$, and we call the additive identity of $(R, +)$ zero, written as $0_{R}$ or $0$

\textbf{Example}: We can define the \textbf{null ring} or \textbf{zero ring} as a ring where $R$ is a single ement set, e.g. $\{0\}$, with the operations $0 + 0 = 0$ and $0 \times 0 = 0$. We will call any ring that isn't the zero ring a \textbf{non-zero ring}

\begin{xmp}[Modulo Rings]{xmp:modulo-rings}{}
    Let $m\in \mathbb{Z}$ be an integer. Then the set of \textbf{integers modulo} $m$, written
    \[\mathbb{Z} / m\mathbb{Z}\]
    is a ring. The elements of $\mathbb{Z} / m\mathbb{Z}$ consist of \textbf{congruence classes} of integers modulo $m$ - that is the elements are the subsets $T$ of $\mathbb{Z}$ of the form $T = a + m\mathbb{Z}$ with $a\in \mathbb{Z}$. Think of these as the set of integers that have the same remainder when you divide them by $m$. I denote the above congruence class by $\overline{a}$. Obviously $\overline{a} = \overline{b}$ is the same as $a-b\in m\mathbb{Z}$, and often I'll write
    \[a \equiv b \mod m\]
\end{xmp}

If $m\in \mathbb{N}_{\ge 0}$ then there are $m$ congruence classes modulo $m$, in other words, $\lvert \mathbb{Z} / m\mathbb{Z} \rvert = m$, and I could write out the set as
\[\mathbb{Z} / m\mathbb{Z} = \{\overline{0}, \overline{1},\dots,\overline{m - 1}\}\]
To define addition and multiplication, set
\[\overline{a} + \overline{b} = \overline{a + b} \quad \text{and} \quad \overline{a} \cdot \overline{b} = \overline{ab}\]
Distributivity for $\mathbb{Z} / m\mathbb{Z}$ then follows from distributivity for $\mathbb{Z}$.

\newpage
\subsection{Linking Rings to Fields and Further Properties}

\begin{dfn}[Ring definition of a field]{def:field-ring}{}
    A \textbf{field} is a non-zero commutative ring $F$ in which every non-zero element $a\in F$ has an inverse $a^{-1}\in F$, that is an element $a^{-1}$ with the property that $a \cdot a^{-1} = a^{-1} \cdot a = 1$
\end{dfn}

\textbf{Example}: The ring $\mathbb{Z} / 3\mathbb{Z}$ is a field, which we have been calling $\mathbb{F}_{3}$. The ring $\mathbb{Z} / 12\mathbb{Z}$ is not a field, because neither $\overline{3}$ or $\overline{8}$ are invertible, since $\overline{3} \cdot \overline{8} = \overline{0}$.

\begin{thm}[Prime property of fields]{thm:prime-ring-fields}{}
    Let $m$ be a positive integer. The commutative ring $\mathbb{Z} / m\mathbb{Z}$ is a field if and only if $m$ is prime.
\end{thm}

\begin{thm}[Lemmas for multiplying by zero and negatives]{def:ring-lemmas-1}{}
    Let $R$ be a ring and let $a,b\in R$. Then
    \begin{enumerate}
        \item $0a = 0 = a 0$
        \item $(-a)b = -(ab) = a(-b)$
        \item $(-a)(-b) = ab)$
    \end{enumerate}
\end{thm}

\textbf{Note}: The distributive axiom for rings has familiar properties such as
\begin{align*}
    (a + b)(c + d) &= ac + ad + bc + bd\\
    a(b - c) &= ab - ac
\end{align*}
But remember that multiplication is not always commutative, so multiplicative factors must be kept in the correct order - $ac$ may not equal $ca$

\noindent\rule{\textwidth}{0.2pt}
Suppose we have a ring $R$ such that $1_{R} = 0_{R}$, then $R$ must be the zero ring. 3.2.2 in notes for proof

\begin{dfn}[Multiples of an abelian group]{def:abelian-group-multis}{}
    Let $m\in \mathbb{Z}$. The \textbf{$m$-th multiple $ma$ of an element $a$}in an abelian group $R$ is:
    \[ma = \underbrace{a + a + \cdots + a}_{\text{$m$ terms}} \quad \text{if} m > 0\]
    $0a = 0$ and negative multiples are defined by $(-m)a = -(ma)$
\end{dfn}

\newpage
\begin{thm}[Lemmas for multiples]{def:ring-lemmas-2}{}
    Let $R$ be a ring, let $a,b\in R$ and let $m,n\in \mathbb{Z}$. Then:
    \begin{enumerate}
        \item $m(a + b) = ma + mb$
        \item $(m + n)a = ma + na$
        \item $m(na) = (mn)a$
        \item $m(ab) = (ma)b = a(mb)$
        \item $(ma)(nb) = (mn)(ab)$
    \end{enumerate}
\end{thm}

\begin{proof}
    (in the lecturer's words) This is trivial and boring, so I will leave the details up to you.
\end{proof}

\begin{dfn}[Unit of a ring]{def:ring-unit}{}
    Let $R$ be a ring. An element $a\in R$ is called a \textbf{unit} if it is \textit{invertible} in $R$ or in other words \textit{has a multiplicative inverse in $R$}, meaning that there exists $a^{-1}\in R$ such that
    \[aa^{-1} = 1 = a^{-1} a\]
\end{dfn}

\textbf{Example}: In a field, such as $\mathbb{R}, \mathbb{R}, \mathbb{C}$, every non-zero element is a unit. In $\mathbb{Z}$, only $1$ and $-1$ are units

\begin{thm}[The subset of units in a ring forms a group]{thm:ring-units-form-a-group}{}
    The set $R^{\times}$ of units in a ring $R$ forms a group under multiplication
\end{thm}

I will call $R^{\times}$ the \textbf{group of units of the ring $R$}

\begin{dfn}[zero-divisors of a ring]{def:zero-divisor}{}
    In a ring $R$, a non-zero element $a$ is called a \textbf{zero-divisor} or \textbf{divisor of zero} if there exists a non-zero element $b$ such that either $ab = 0$ or $ba = 0$.
\end{dfn}

\textbf{Example}: In $\text{Mat}(2; \mathbb{R})$,
\[\begin{bmatrix}
    -1& 1\\
    -1& 1
\end{bmatrix} \begin{bmatrix}
    1& 1\\
    1& 1
\end{bmatrix} = \begin{bmatrix}
    0& 0\\
    0& 0
\end{bmatrix}\]
So, both $\begin{bmatrix}
    -1& 1\\
    -1& 1
\end{bmatrix}$ and $\begin{bmatrix}
    1& 1\\
    1& 1
\end{bmatrix}$ are zero-divisors


\begin{dfn}[Integral Domain]{def:integral-domain}{}
    An \textbf{integral domain} is a non-zero commutative ring that has no zero-divisors.

    In an integral domain there are no zero-divisors and therefore the following laws will hold:
    \begin{enumerate}
        \item $ab = 0 \implies a = 0$ or $b = 0$, and
        \item $a\ne 0$ and $b\ne 0 \implies ab \ne 0$ 
    \end{enumerate}
\end{dfn}

\textbf{Example}: $\mathbb{Z}$ is an integral domain. Any field is an integral domain, since a unit in a ring $R$ cannot be a zero-divisor. To see this, let $R$ be a non-zero ring and let $a\in R^{\times}$ be a unit. Suppose that $ab = 0$ or $ba = 0$ for some $b\in R$. Multiplying on the left or on the right respectively by $a^{-1}$ shows that $a^{-1} ab = a^{-1} 0$ or $baa^{-1} = 0 a^{-1}$, so in both cases, $b = 0$

\begin{thm}[Cancellation Law for Integral Domains]{thm:int-domains-cancellation-law}{}
    Let $R$ be an \textit{integral domain} and let $a,b,c\in R$. If $ab = ac$ and $a\ne 0$ then $b = c$
\end{thm}

We will now reprove \ref{thm:prime-ring-fields} as a special case of a general theorem

\begin{thm}[Prime Property for Integral Domains]{thm:prime-int-domains}{}
    Let $m$ be a natural number. Then $\mathbb{Z} / m\mathbb{Z}$ is an integral domain if and only if $m$ is prime.
\end{thm}

\begin{thm}[Finite Integral Domains are Fields]{thm:finite-int-domains-are-fields}{}
    Every \textbf{finite} \hyperref[def:integral-domain]{integral domain} is a \hyperref[def:field]{field}.
\end{thm}

\subsection{Polynomials}

\end{document}
